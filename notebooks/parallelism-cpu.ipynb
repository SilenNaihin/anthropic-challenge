{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-1",
   "metadata": {},
   "source": [
    "# CPU Parallelism: SIMD and VLIW\n",
    "\n",
    "You know that CPUs execute instructions. You may have heard that modern CPUs do billions of operations per second. But have you ever wondered: how do they actually achieve such throughput?\n",
    "\n",
    "The answer is parallelism - doing multiple things at once. But there are different *kinds* of parallelism that work at different levels. This notebook builds up the intuition for two key forms: **SIMD** and **VLIW**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import time\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "problem-intro",
   "metadata": {},
   "source": [
    "## The Problem: Sequential Execution is Slow\n",
    "\n",
    "Let's start with a concrete problem. Say we have 8 numbers and we want to double each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequential-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input data: 8 numbers\n",
    "input_values = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "print(f\"Input: {input_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequential-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The naive approach: process one at a time\n",
    "output_values = []\n",
    "for val in input_values:\n",
    "    doubled = val * 2\n",
    "    output_values.append(doubled)\n",
    "\n",
    "print(f\"Output: {output_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cycle-counting",
   "metadata": {},
   "source": "This works, but let's think about what the CPU is actually doing. Each iteration requires:\n1. Load the value from memory\n2. Multiply by 2\n3. Store the result\n\n**What's a cycle?** A CPU operates on a clock - millions or billions of \"ticks\" per second. A **cycle** is one tick of this clock. Simple operations like addition or multiplication typically complete in 1 cycle. A 3 GHz CPU has 3 billion cycles per second.\n\nIf each operation takes 1 cycle, processing 8 values takes **24 cycles** (8 loads + 8 multiplies + 8 stores).\n\nLet's simulate this to see the timeline:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequential-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sequential execution\n",
    "def simulate_sequential(n_values):\n",
    "    \"\"\"Returns list of (cycle, operation, value_index)\"\"\"\n",
    "    timeline = []\n",
    "    cycle = 0\n",
    "    for i in range(n_values):\n",
    "        timeline.append((cycle, 'load', i))\n",
    "        cycle += 1\n",
    "        timeline.append((cycle, 'multiply', i))\n",
    "        cycle += 1\n",
    "        timeline.append((cycle, 'store', i))\n",
    "        cycle += 1\n",
    "    return timeline, cycle\n",
    "\n",
    "timeline_seq, total_cycles_seq = simulate_sequential(8)\n",
    "print(f\"Sequential execution: {total_cycles_seq} cycles for 8 values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-sequential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sequential timeline\n",
    "def plot_timeline(timeline, title, max_cycles=None):\n",
    "    fig, ax = plt.subplots(figsize=(14, 3))\n",
    "    \n",
    "    colors = {'load': '#3498db', 'multiply': '#e74c3c', 'store': '#2ecc71'}\n",
    "    y_positions = {'load': 2, 'multiply': 1, 'store': 0}\n",
    "    \n",
    "    for cycle, op, idx in timeline:\n",
    "        y = y_positions[op]\n",
    "        rect = plt.Rectangle((cycle, y), 0.9, 0.8, \n",
    "                             facecolor=colors[op], edgecolor='black', linewidth=0.5)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(cycle + 0.45, y + 0.4, f'v{idx}', ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    max_x = max_cycles if max_cycles else max(c for c, _, _ in timeline) + 2\n",
    "    ax.set_xlim(-0.5, max_x)\n",
    "    ax.set_ylim(-0.5, 3.5)\n",
    "    ax.set_xlabel('Cycle')\n",
    "    ax.set_yticks([0.4, 1.4, 2.4])\n",
    "    ax.set_yticklabels(['Store', 'Multiply', 'Load'])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    # Legend\n",
    "    patches = [mpatches.Patch(color=c, label=l) for l, c in colors.items()]\n",
    "    ax.legend(handles=patches, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "plot_timeline(timeline_seq, f'Sequential Execution: {total_cycles_seq} cycles', max_cycles=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequential-problem",
   "metadata": {},
   "source": [
    "Look at all that wasted potential! At any given cycle, only ONE operation is happening. The multiply hardware sits idle while we load. The store hardware sits idle while we multiply.\n",
    "\n",
    "**What if we could do all 8 multiplies at once?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simd-intro",
   "metadata": {},
   "source": [
    "## SIMD: Single Instruction, Multiple Data\n",
    "\n",
    "Here's a key insight: look at what we're doing to each value.\n",
    "\n",
    "- value 0: multiply by 2\n",
    "- value 1: multiply by 2\n",
    "- value 2: multiply by 2\n",
    "- ... and so on\n",
    "\n",
    "We're doing **the same operation** on **different data**. This pattern is incredibly common:\n",
    "- Adding two vectors element-wise\n",
    "- Scaling all pixels in an image\n",
    "- Computing activations in a neural network layer\n",
    "\n",
    "What if we had hardware that could execute one instruction on multiple values simultaneously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simd-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptually: instead of 8 separate multiplies...\n",
    "print(\"Sequential thinking:\")\n",
    "for i, val in enumerate(input_values):\n",
    "    print(f\"  Cycle {i}: multiply value[{i}] = {val} * 2 = {val * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simd-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...we do all 8 at once!\n",
    "print(\"SIMD thinking (all in ONE cycle):\")\n",
    "print(f\"  multiply value[0..7] = {input_values}\")\n",
    "print(f\"                      * [2, 2, 2, 2, 2, 2, 2, 2]\")\n",
    "print(f\"                      = {[v*2 for v in input_values]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simd-hardware",
   "metadata": {},
   "source": [
    "This is called **SIMD**: Single Instruction, Multiple Data.\n",
    "\n",
    "- **Single Instruction**: One \"multiply\" command\n",
    "- **Multiple Data**: Applied to 8 values simultaneously\n",
    "\n",
    "The hardware has 8 ALUs (Arithmetic Logic Units) working in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-simd-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SIMD hardware concept\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Draw 8 ALUs side by side\n",
    "alu_width = 1.2\n",
    "alu_height = 1.0\n",
    "spacing = 0.3\n",
    "\n",
    "for i in range(8):\n",
    "    x = i * (alu_width + spacing)\n",
    "    \n",
    "    # Input arrow\n",
    "    ax.annotate('', xy=(x + alu_width/2, 3.5), xytext=(x + alu_width/2, 4.2),\n",
    "                arrowprops=dict(arrowstyle='->', color='#3498db', lw=2))\n",
    "    ax.text(x + alu_width/2, 4.4, f'{input_values[i]}', ha='center', fontsize=10, color='#3498db')\n",
    "    \n",
    "    # ALU box\n",
    "    rect = FancyBboxPatch((x, 2.5), alu_width, alu_height, \n",
    "                          boxstyle=\"round,pad=0.05\", facecolor='#e74c3c', edgecolor='black')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + alu_width/2, 3.0, f'ALU {i}', ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "    \n",
    "    # Operation label\n",
    "    ax.text(x + alu_width/2, 2.1, 'x2', ha='center', fontsize=9)\n",
    "    \n",
    "    # Output arrow\n",
    "    ax.annotate('', xy=(x + alu_width/2, 1.0), xytext=(x + alu_width/2, 1.8),\n",
    "                arrowprops=dict(arrowstyle='->', color='#2ecc71', lw=2))\n",
    "    ax.text(x + alu_width/2, 0.7, f'{input_values[i]*2}', ha='center', fontsize=10, color='#2ecc71')\n",
    "\n",
    "# Title and labels\n",
    "ax.text(5.5, 5.2, 'SIMD: 8 ALUs execute the SAME instruction on DIFFERENT data', \n",
    "        ha='center', fontsize=12, fontweight='bold')\n",
    "ax.text(5.5, 4.8, '(All in ONE cycle!)', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "ax.set_xlim(-0.5, 12)\n",
    "ax.set_ylim(0, 5.5)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vlen-intro",
   "metadata": {},
   "source": [
    "### VLEN: The Vector Length\n",
    "\n",
    "How many values can we process at once? This is called the **vector length** or **VLEN**.\n",
    "\n",
    "Different CPUs have different VLEN:\n",
    "- Intel SSE: 4 floats (128 bits)\n",
    "- Intel AVX: 8 floats (256 bits)\n",
    "- Intel AVX-512: 16 floats (512 bits)\n",
    "- Our challenge machine: **VLEN = 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vlen-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "VLEN = 8  # Our challenge machine's vector length\n",
    "print(f\"VLEN = {VLEN}\")\n",
    "print(f\"One vector instruction processes {VLEN} values at once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vdbgx9zxgo8",
   "source": "### What About Non-Multiples of VLEN?\n\nReal data rarely comes in perfect multiples of 8. What happens if we have 9 elements?\n\nThe answer: we need **tail handling**. The last partial batch (elements 8) still uses a vector instruction, but with a **mask** that only processes the valid elements:\n\n- Elements 0-7: Full vector operation (all 8 lanes active)\n- Element 8: Partial vector operation (only 1 lane active, 7 lanes masked off)\n\nThis is handled automatically by modern vector ISAs, but it's worth knowing: if your data size is just slightly over a VLEN multiple (e.g., 9 or 17 elements), you still pay for a full extra vector instruction.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "simd-speedup",
   "metadata": {},
   "source": [
    "### The SIMD Speedup\n",
    "\n",
    "Let's see how SIMD changes our timeline. Instead of 8 separate multiply instructions, we have ONE vector multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simd-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate SIMD execution (still sequential load-compute-store, but vectorized)\n",
    "def simulate_simd_simple(n_values, vlen=8):\n",
    "    \"\"\"SIMD version: process VLEN values per instruction\"\"\"\n",
    "    timeline = []\n",
    "    cycle = 0\n",
    "    \n",
    "    for chunk_start in range(0, n_values, vlen):\n",
    "        chunk_end = min(chunk_start + vlen, n_values)\n",
    "        # Vector load\n",
    "        for i in range(chunk_start, chunk_end):\n",
    "            timeline.append((cycle, 'load', i))\n",
    "        cycle += 1\n",
    "        # Vector multiply\n",
    "        for i in range(chunk_start, chunk_end):\n",
    "            timeline.append((cycle, 'multiply', i))\n",
    "        cycle += 1\n",
    "        # Vector store\n",
    "        for i in range(chunk_start, chunk_end):\n",
    "            timeline.append((cycle, 'store', i))\n",
    "        cycle += 1\n",
    "    \n",
    "    return timeline, cycle\n",
    "\n",
    "timeline_simd, total_cycles_simd = simulate_simd_simple(8)\n",
    "print(f\"SIMD execution: {total_cycles_simd} cycles for 8 values\")\n",
    "print(f\"Speedup: {total_cycles_seq / total_cycles_simd:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-simd-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SIMD timeline - all 8 values in each operation\n",
    "def plot_simd_timeline(timeline, title, vlen=8):\n",
    "    fig, ax = plt.subplots(figsize=(14, 3))\n",
    "    \n",
    "    colors = {'load': '#3498db', 'multiply': '#e74c3c', 'store': '#2ecc71'}\n",
    "    y_positions = {'load': 2, 'multiply': 1, 'store': 0}\n",
    "    \n",
    "    # Group by cycle and operation\n",
    "    from collections import defaultdict\n",
    "    grouped = defaultdict(list)\n",
    "    for cycle, op, idx in timeline:\n",
    "        grouped[(cycle, op)].append(idx)\n",
    "    \n",
    "    for (cycle, op), indices in grouped.items():\n",
    "        y = y_positions[op]\n",
    "        width = 0.9\n",
    "        rect = plt.Rectangle((cycle, y), width, 0.8, \n",
    "                             facecolor=colors[op], edgecolor='black', linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "        label = f'v0-v{len(indices)-1}' if len(indices) > 1 else f'v{indices[0]}'\n",
    "        ax.text(cycle + width/2, y + 0.4, label, ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    max_x = max(c for c, _, _ in timeline) + 2\n",
    "    ax.set_xlim(-0.5, 26)\n",
    "    ax.set_ylim(-0.5, 3.5)\n",
    "    ax.set_xlabel('Cycle')\n",
    "    ax.set_yticks([0.4, 1.4, 2.4])\n",
    "    ax.set_yticklabels(['Store', 'Multiply', 'Load'])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "plot_simd_timeline(timeline_simd, f'SIMD Execution: {total_cycles_simd} cycles (vs {total_cycles_seq} sequential)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simd-comparison",
   "metadata": {},
   "source": [
    "Whoa! We went from 24 cycles to 3 cycles - an **8x speedup**. This is exactly VLEN.\n",
    "\n",
    "But wait... look at the timeline again. At cycle 0, only the load hardware is working. At cycle 1, only the multiply hardware is working. At cycle 2, only the store hardware is working.\n",
    "\n",
    "**These are different pieces of hardware. Why can't they work simultaneously?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numpy-simd",
   "metadata": {},
   "source": [
    "### Real-World SIMD: What NumPy Does Under the Hood\n",
    "\n",
    "When you write vectorized NumPy code, it's using SIMD instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numpy-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy's vectorized operations use SIMD under the hood\n",
    "arr = np.array([10, 20, 30, 40, 50, 60, 70, 80], dtype=np.int32)\n",
    "result = arr * 2  # This compiles to SIMD instructions!\n",
    "print(f\"NumPy: {arr} * 2 = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numpy-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the difference with a larger array\n",
    "large_arr = np.random.randn(1_000_000).astype(np.float32)\n",
    "\n",
    "# Python loop (no SIMD)\n",
    "def python_loop(arr):\n",
    "    result = []\n",
    "    for x in arr:\n",
    "        result.append(x * 2)\n",
    "    return result\n",
    "\n",
    "# Time both approaches\n",
    "start = time.time()\n",
    "_ = python_loop(large_arr.tolist())\n",
    "python_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = large_arr * 2\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "print(f\"Python loop: {python_time*1000:.1f} ms\")\n",
    "print(f\"NumPy (SIMD): {numpy_time*1000:.2f} ms\")\n",
    "print(f\"Speedup: {python_time/numpy_time:.0f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numpy-insight",
   "metadata": {},
   "source": "The massive speedup comes from multiple factors working together:\n\n1. **SIMD instructions**: NumPy operations compile to vector instructions that process 4, 8, or 16 values per CPU cycle\n2. **Avoiding Python overhead**: No interpreter dispatch, type checking, or object boxing per element\n3. **Memory locality**: Contiguous arrays enable efficient cache usage and prefetching\n4. **Compiled C code**: NumPy's core loops are pre-compiled, not interpreted\n\nSIMD is a significant contributor, but even without SIMD, avoiding Python's per-element overhead would give substantial speedups.\n\n**This is why \"vectorize your code\" is such important advice.** When you write a Python loop over array elements, you're throwing away all of these optimizations."
  },
  {
   "cell_type": "markdown",
   "id": "practice-simd",
   "metadata": {},
   "source": [
    "### Practice: Vectorize This Loop\n",
    "\n",
    "Convert the following loop to use NumPy's vectorized operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-simd-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given: compute (a + b) * c for each element\n",
    "a = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "b = np.array([10, 20, 30, 40, 50, 60, 70, 80])\n",
    "c = np.array([2, 2, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "# The slow way:\n",
    "result_loop = []\n",
    "for i in range(len(a)):\n",
    "    result_loop.append((a[i] + b[i]) * c[i])\n",
    "result_loop = np.array(result_loop)\n",
    "print(f\"Loop result: {result_loop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-simd-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your vectorized solution:\n",
    "test_result_vectorized = (a + b) * c  # Replace with your answer\n",
    "\n",
    "# Verify\n",
    "assert np.allclose(test_result_vectorized, result_loop), \"Results don't match!\"\n",
    "print(f\"Vectorized result: {test_result_vectorized}\")\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vector-registers-intro",
   "metadata": {},
   "source": [
    "## Vector Registers and vload/vstore\n",
    "\n",
    "To do SIMD operations, we need a place to hold multiple values at once. This is where **vector registers** come in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scalar-vs-vector",
   "metadata": {},
   "source": [
    "### Scalar vs Vector Registers\n",
    "\n",
    "- **Scalar register**: Holds ONE value (like a regular variable)\n",
    "- **Vector register**: Holds VLEN values (like a small array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "register-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual comparison\n",
    "scalar_register = 42  # One value\n",
    "print(f\"Scalar register: {scalar_register}\")\n",
    "\n",
    "vector_register = [10, 20, 30, 40, 50, 60, 70, 80]  # VLEN=8 values\n",
    "print(f\"Vector register: {vector_register}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-registers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "\n",
    "# Scalar register\n",
    "ax = axes[0]\n",
    "rect = plt.Rectangle((0.3, 0.3), 0.4, 0.4, facecolor='#3498db', edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(0.5, 0.5, '42', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Scalar Register\\n(holds 1 value)', fontsize=12)\n",
    "ax.axis('off')\n",
    "\n",
    "# Vector register\n",
    "ax = axes[1]\n",
    "for i in range(8):\n",
    "    rect = plt.Rectangle((i * 0.12 + 0.02, 0.3), 0.11, 0.4, \n",
    "                         facecolor='#e74c3c', edgecolor='black')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(i * 0.12 + 0.075, 0.5, f'{(i+1)*10}', ha='center', va='center', fontsize=10)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(f'Vector Register\\n(holds {VLEN} values)', fontsize=12)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vload-vstore",
   "metadata": {},
   "source": [
    "### vload and vstore: Moving Data In and Out\n",
    "\n",
    "To work with vector registers, we need special instructions:\n",
    "\n",
    "- **vload**: Load VLEN contiguous values from memory into a vector register\n",
    "- **vstore**: Store VLEN values from a vector register to contiguous memory locations\n",
    "\n",
    "The key word is **contiguous** - the values must be next to each other in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vload-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate memory and vload/vstore\n",
    "memory = [0] * 20  # Memory with 20 slots\n",
    "memory[4:12] = [10, 20, 30, 40, 50, 60, 70, 80]  # Our data at addresses 4-11\n",
    "\n",
    "print(\"Memory layout:\")\n",
    "for i in range(0, 20, 4):\n",
    "    chunk = memory[i:i+4]\n",
    "    print(f\"  addr {i:2d}-{i+3:2d}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vload-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vload: Load 8 contiguous values starting at address 4\n",
    "def vload(memory, start_addr, vlen=8):\n",
    "    \"\"\"Load VLEN contiguous values from memory\"\"\"\n",
    "    return memory[start_addr : start_addr + vlen]\n",
    "\n",
    "vector_reg = vload(memory, start_addr=4)\n",
    "print(f\"vload from addr 4: {vector_reg}\")\n",
    "print(f\"  -> Loaded {len(vector_reg)} values in ONE instruction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vstore-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vstore: Store 8 values to contiguous memory locations\n",
    "def vstore(memory, start_addr, values, vlen=8):\n",
    "    \"\"\"Store VLEN values to contiguous memory\"\"\"\n",
    "    for i in range(vlen):\n",
    "        memory[start_addr + i] = values[i]\n",
    "\n",
    "# Double our values\n",
    "doubled = [v * 2 for v in vector_reg]\n",
    "print(f\"After doubling: {doubled}\")\n",
    "\n",
    "# Store to addresses 12-19\n",
    "vstore(memory, start_addr=12, values=doubled)\n",
    "\n",
    "print(\"\\nMemory after vstore:\")\n",
    "for i in range(0, 20, 4):\n",
    "    chunk = memory[i:i+4]\n",
    "    print(f\"  addr {i:2d}-{i+3:2d}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contiguous-importance",
   "metadata": {},
   "source": [
    "### Why Contiguous Matters\n",
    "\n",
    "Think of vload like reaching onto a bookshelf and grabbing 8 books at once. This only works if the books are next to each other!\n",
    "\n",
    "If your data is scattered (non-contiguous), you can't use vload - you'd have to load each value individually, losing the SIMD benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-contiguous",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize contiguous vs scattered\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 3))\n",
    "\n",
    "# Contiguous - vload works!\n",
    "ax = axes[0]\n",
    "for i in range(16):\n",
    "    color = '#e74c3c' if 4 <= i < 12 else '#ecf0f1'\n",
    "    rect = plt.Rectangle((i * 0.06, 0.3), 0.055, 0.4, facecolor=color, edgecolor='black')\n",
    "    ax.add_patch(rect)\n",
    "    if 4 <= i < 12:\n",
    "        ax.text(i * 0.06 + 0.0275, 0.5, f'{(i-3)*10}', ha='center', va='center', fontsize=8)\n",
    "ax.annotate('', xy=(0.24, 0.25), xytext=(0.72, 0.25),\n",
    "            arrowprops=dict(arrowstyle='<->', color='green', lw=2))\n",
    "ax.text(0.48, 0.1, 'ONE vload', ha='center', fontsize=10, color='green', fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Contiguous data: vload grabs all 8 at once', fontsize=11)\n",
    "ax.axis('off')\n",
    "\n",
    "# Scattered - need individual loads\n",
    "ax = axes[1]\n",
    "scattered_indices = [0, 2, 5, 6, 9, 11, 13, 15]  # Non-contiguous!\n",
    "for i in range(16):\n",
    "    color = '#e74c3c' if i in scattered_indices else '#ecf0f1'\n",
    "    rect = plt.Rectangle((i * 0.06, 0.3), 0.055, 0.4, facecolor=color, edgecolor='black')\n",
    "    ax.add_patch(rect)\n",
    "for j, i in enumerate(scattered_indices[:4]):\n",
    "    ax.annotate('', xy=(i * 0.06 + 0.0275, 0.25), xytext=(i * 0.06 + 0.0275, 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "ax.text(0.48, 0.02, '8 separate loads needed!', ha='center', fontsize=10, color='red', fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Scattered data: cannot use vload', fontsize=11)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-layout-lesson",
   "metadata": {},
   "source": [
    "This is why **data layout matters so much for performance**. If you're designing data structures for high-performance code, you want related values stored contiguously so SIMD can work efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vliw-intro",
   "metadata": {},
   "source": [
    "## VLIW: Very Long Instruction Word\n",
    "\n",
    "We've seen SIMD: doing the same operation on multiple data. But there's another form of parallelism hiding in plain sight.\n",
    "\n",
    "Look back at our SIMD timeline. Even with SIMD, we're executing operations in sequence:\n",
    "1. Cycle 0: vload (8 values)\n",
    "2. Cycle 1: multiply (8 values)\n",
    "3. Cycle 2: vstore (8 values)\n",
    "\n",
    "But wait - **loads, arithmetic, and stores use different hardware circuits!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hardware-units",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CPU has different \"engines\" - separate pieces of hardware\n",
    "cpu_engines = {\n",
    "    'ALU': 'Does arithmetic: add, multiply, shift, etc.',\n",
    "    'Load Unit': 'Fetches data from memory into registers',\n",
    "    'Store Unit': 'Writes data from registers to memory',\n",
    "    'Flow Control': 'Handles jumps, branches, conditionals'\n",
    "}\n",
    "\n",
    "print(\"CPU has separate hardware engines:\")\n",
    "for engine, desc in cpu_engines.items():\n",
    "    print(f\"  {engine}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-engines",
   "metadata": {},
   "source": [
    "Here's the key insight: **while the ALU is computing, the Load Unit could be fetching the NEXT batch of data!**\n",
    "\n",
    "This is called **VLIW: Very Long Instruction Word**. Instead of one operation per cycle, we pack multiple operations (using different hardware) into a single \"instruction bundle.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vliw-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional: one operation per instruction\n",
    "traditional_program = [\n",
    "    \"load v0 from addr 0\",\n",
    "    \"multiply v0 by 2\", \n",
    "    \"store v0 to addr 8\",\n",
    "]\n",
    "print(\"Traditional (3 cycles):\")\n",
    "for i, instr in enumerate(traditional_program):\n",
    "    print(f\"  Cycle {i}: {instr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u3vua3t167q",
   "source": "### The Dependency Constraint\n\nHere's the catch: not all operations can run in parallel. Consider:\n\n```\nload v0 from memory    # Step 1: Load data into v0\nmultiply v0 by 2       # Step 2: Use v0 (depends on step 1!)\nstore v0 to memory     # Step 3: Store v0 (depends on step 2!)\n```\n\nYou can't multiply v0 before you've loaded it. You can't store the result before you've computed it. These are **data dependencies** - each step needs the result of the previous step.\n\nSo what CAN run in parallel? Operations on DIFFERENT data! If we're processing multiple batches, we can:\n- Load batch N+1 (into v1) while we compute batch N (in v0)\n- The load and compute use different registers, so no conflict!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vliw-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLIW: bundle multiple operations that use different hardware\n",
    "vliw_instruction = {\n",
    "    'load': 'load v1 from addr 8',      # Load Unit\n",
    "    'alu': 'multiply v0 by 2',           # ALU\n",
    "    'store': 'store v_prev to addr 0',   # Store Unit\n",
    "}\n",
    "print(\"VLIW instruction bundle (ALL in ONE cycle):\")\n",
    "for engine, op in vliw_instruction.items():\n",
    "    print(f\"  {engine:6s}: {op}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-vliw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize VLIW - multiple engines working in parallel\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "engines = ['Load Unit', 'ALU', 'Store Unit']\n",
    "colors = {'Load Unit': '#3498db', 'ALU': '#e74c3c', 'Store Unit': '#2ecc71'}\n",
    "\n",
    "# Draw the engines\n",
    "for i, engine in enumerate(engines):\n",
    "    y = i * 1.5\n",
    "    rect = FancyBboxPatch((0.5, y), 2, 1, boxstyle=\"round,pad=0.05\",\n",
    "                          facecolor=colors[engine], edgecolor='black')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(1.5, y + 0.5, engine, ha='center', va='center', \n",
    "            fontsize=12, fontweight='bold', color='white')\n",
    "\n",
    "# Draw the instruction bundle\n",
    "ax.annotate('', xy=(3, 2), xytext=(4.5, 3.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "ax.annotate('', xy=(3, 2), xytext=(4.5, 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "ax.annotate('', xy=(3, 2), xytext=(4.5, 0.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "\n",
    "# Instruction text\n",
    "ax.text(5.5, 3.5, 'vload v1, addr', fontsize=10, va='center')\n",
    "ax.text(5.5, 2, 'vmul v0, v0, 2', fontsize=10, va='center')\n",
    "ax.text(5.5, 0.5, 'vstore addr, v_prev', fontsize=10, va='center')\n",
    "\n",
    "# Bundle box\n",
    "rect = plt.Rectangle((4.3, 0), 4, 4), \n",
    "ax.add_patch(plt.Rectangle((4.3, 0), 4, 4, fill=False, edgecolor='black', \n",
    "                           linestyle='--', linewidth=2))\n",
    "ax.text(6.3, 4.3, 'ONE Instruction Bundle', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(6.3, -0.4, '(All execute in ONE cycle)', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "ax.set_xlim(0, 9)\n",
    "ax.set_ylim(-1, 5)\n",
    "ax.set_title('VLIW: Different engines work in parallel', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vliw-pipelining",
   "metadata": {},
   "source": [
    "### The Pipeline Pattern\n",
    "\n",
    "With VLIW, we can create a **pipeline** where different stages of processing happen simultaneously on different data:\n",
    "\n",
    "| Cycle | Load Unit | ALU | Store Unit |\n",
    "|-------|-----------|-----|------------|\n",
    "| 0 | Load batch 0 | (idle) | (idle) |\n",
    "| 1 | Load batch 1 | Compute batch 0 | (idle) |\n",
    "| 2 | Load batch 2 | Compute batch 1 | Store batch 0 |\n",
    "| 3 | Load batch 3 | Compute batch 2 | Store batch 1 |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "After the pipeline fills up, we're processing ONE BATCH PER CYCLE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate pipelined VLIW execution\n",
    "def simulate_vliw_pipeline(n_batches):\n",
    "    \"\"\"VLIW with overlapping load/compute/store\"\"\"\n",
    "    schedule = []  # (cycle, engine, batch)\n",
    "    \n",
    "    for batch in range(n_batches):\n",
    "        # Each batch goes through 3 stages, but stages overlap!\n",
    "        schedule.append((batch, 'load', batch))      # Load starts at cycle=batch\n",
    "        schedule.append((batch + 1, 'compute', batch))  # Compute at cycle=batch+1\n",
    "        schedule.append((batch + 2, 'store', batch))    # Store at cycle=batch+2\n",
    "    \n",
    "    total_cycles = n_batches + 2  # Pipeline fill + drain\n",
    "    return schedule, total_cycles\n",
    "\n",
    "schedule, total_cycles = simulate_vliw_pipeline(4)\n",
    "print(f\"Processing 4 batches with pipelined VLIW: {total_cycles} cycles\")\n",
    "print(f\"\\nWithout pipelining: 4 * 3 = 12 cycles\")\n",
    "print(f\"Speedup from pipelining: {12/total_cycles:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pipeline\n",
    "def plot_pipeline(schedule, n_cycles, title):\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    \n",
    "    colors = {'load': '#3498db', 'compute': '#e74c3c', 'store': '#2ecc71'}\n",
    "    y_positions = {'load': 2, 'compute': 1, 'store': 0}\n",
    "    \n",
    "    for cycle, engine, batch in schedule:\n",
    "        y = y_positions[engine]\n",
    "        rect = plt.Rectangle((cycle, y), 0.9, 0.8, \n",
    "                             facecolor=colors[engine], edgecolor='black', linewidth=1, alpha=0.8)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(cycle + 0.45, y + 0.4, f'B{batch}', ha='center', va='center', \n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(-0.5, n_cycles + 0.5)\n",
    "    ax.set_ylim(-0.5, 3.5)\n",
    "    ax.set_xlabel('Cycle', fontsize=11)\n",
    "    ax.set_yticks([0.4, 1.4, 2.4])\n",
    "    ax.set_yticklabels(['Store Unit', 'ALU', 'Load Unit'])\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    # Legend\n",
    "    patches = [mpatches.Patch(color=c, label=l) for l, c in colors.items()]\n",
    "    ax.legend(handles=patches, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "plot_pipeline(schedule, 7, 'VLIW Pipeline: All engines stay busy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-insight",
   "metadata": {},
   "source": [
    "Look at cycles 2-4: **all three engines are working simultaneously!** This is the power of VLIW.\n",
    "\n",
    "- Load Unit is fetching batch N+2\n",
    "- ALU is computing batch N+1\n",
    "- Store Unit is saving batch N\n",
    "\n",
    "After the initial \"ramp up,\" we achieve **one batch of work per cycle** instead of **three cycles per batch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slots-intro",
   "metadata": {},
   "source": [
    "## Engine Slots: How Many Ops Per Cycle?\n",
    "\n",
    "So far we've talked about engines like they can only do one thing at a time. But real hardware often has **multiple slots** per engine - meaning you can do multiple operations of the same type per cycle.\n",
    "\n",
    "Our challenge machine has these slot limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slot-limits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "SLOT_LIMITS = {\n",
    "    \"alu\": 12,      # 12 scalar ALU operations per cycle\n",
    "    \"valu\": 6,      # 6 vector ALU operations per cycle (each processes VLEN values!)\n",
    "    \"load\": 2,      # 2 load operations per cycle\n",
    "    \"store\": 2,     # 2 store operations per cycle\n",
    "    \"flow\": 1,      # 1 flow control operation per cycle\n",
    "}\n",
    "\n",
    "print(\"Slot limits per cycle:\")\n",
    "for engine, slots in SLOT_LIMITS.items():\n",
    "    print(f\"  {engine:6s}: {slots:2d} slot(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-slots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the slot capacity\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "engines = ['alu', 'valu', 'load', 'store', 'flow']\n",
    "colors_eng = {'alu': '#e74c3c', 'valu': '#9b59b6', 'load': '#3498db', \n",
    "              'store': '#2ecc71', 'flow': '#f39c12'}\n",
    "labels = {'alu': 'Scalar ALU', 'valu': 'Vector ALU', 'load': 'Load', \n",
    "          'store': 'Store', 'flow': 'Flow Control'}\n",
    "\n",
    "y = 0\n",
    "for engine in engines:\n",
    "    slots = SLOT_LIMITS[engine]\n",
    "    for s in range(slots):\n",
    "        rect = plt.Rectangle((s * 0.8, y), 0.75, 0.8, \n",
    "                             facecolor=colors_eng[engine], edgecolor='black', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "    ax.text(-0.5, y + 0.4, f'{labels[engine]} ({slots})', ha='right', va='center', fontsize=10)\n",
    "    y += 1.2\n",
    "\n",
    "ax.set_xlim(-4, 10)\n",
    "ax.set_ylim(-0.5, 6.5)\n",
    "ax.set_xlabel('Slot', fontsize=11)\n",
    "ax.set_title('Available slots per cycle\\n(Each box = one operation)', fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slot-implications",
   "metadata": {},
   "source": [
    "This creates an interesting optimization problem: **how do you pack operations to use all available slots?**\n",
    "\n",
    "Look at the imbalance:\n",
    "- We have 12 scalar ALU slots and 6 vector ALU slots (lots of compute!)\n",
    "- But only 2 load and 2 store slots (limited memory bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slot-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: packing operations into one cycle\n",
    "example_instruction = {\n",
    "    \"valu\": [\n",
    "        (\"*\", \"dest0\", \"src0\", \"src1\"),  # Slot 0: multiply\n",
    "        (\"+\", \"dest1\", \"src2\", \"src3\"),  # Slot 1: add\n",
    "    ],\n",
    "    \"load\": [\n",
    "        (\"vload\", \"reg0\", \"addr0\"),      # Slot 0: vector load\n",
    "        (\"vload\", \"reg1\", \"addr1\"),      # Slot 1: vector load\n",
    "    ],\n",
    "    \"store\": [\n",
    "        (\"vstore\", \"addr2\", \"reg2\"),     # Slot 0: vector store\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"Example instruction bundle (ONE cycle):\")\n",
    "for engine, ops in example_instruction.items():\n",
    "    print(f\"\\n  {engine}:\")\n",
    "    for i, op in enumerate(ops):\n",
    "        print(f\"    Slot {i}: {op}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slot-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How efficiently are we using the slots?\n",
    "def analyze_slot_usage(instruction):\n",
    "    print(\"Slot usage analysis:\")\n",
    "    for engine in SLOT_LIMITS:\n",
    "        if engine == 'debug':\n",
    "            continue\n",
    "        used = len(instruction.get(engine, []))\n",
    "        available = SLOT_LIMITS[engine]\n",
    "        utilization = used / available * 100\n",
    "        bar = '#' * used + '.' * (available - used)\n",
    "        print(f\"  {engine:6s}: [{bar}] {used}/{available} ({utilization:.0f}%)\")\n",
    "\n",
    "analyze_slot_usage(example_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slot-scheduling",
   "metadata": {},
   "source": [
    "**The art of high-performance programming on VLIW machines is scheduling operations to maximize slot usage.** If you have lots of arithmetic to do but few loads, you'll be limited by how fast you can get data. If you have complex control flow, that single flow slot becomes the bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combining-intro",
   "metadata": {},
   "source": [
    "## Combining SIMD and VLIW\n",
    "\n",
    "Now we can put both pieces together:\n",
    "\n",
    "- **SIMD** (horizontal parallelism): Do the same operation on VLEN values at once\n",
    "- **VLIW** (vertical parallelism): Do multiple different operations in the same cycle\n",
    "\n",
    "Combined, we can achieve massive throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the theoretical throughput\n",
    "vlen = 8\n",
    "valu_slots = 6\n",
    "\n",
    "values_per_valu_op = vlen  # Each vector op processes VLEN values\n",
    "valu_ops_per_cycle = valu_slots\n",
    "values_computed_per_cycle = values_per_valu_op * valu_ops_per_cycle\n",
    "\n",
    "print(f\"SIMD: Each vector operation processes {vlen} values\")\n",
    "print(f\"VLIW: Can do {valu_slots} vector ALU operations per cycle\")\n",
    "print(f\"Combined: {values_computed_per_cycle} values computed per cycle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-combined",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what happens in ONE cycle with SIMD + VLIW\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Title\n",
    "ax.text(7, 7.5, 'ONE CYCLE: SIMD + VLIW Combined', \n",
    "        ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Vector ALU slots (6 slots, each processing 8 values)\n",
    "ax.text(0.5, 6.5, 'Vector ALU (6 slots):', fontsize=11, fontweight='bold')\n",
    "for slot in range(6):\n",
    "    y_base = 5.5 - slot * 0.9\n",
    "    ax.text(0.5, y_base + 0.2, f'Slot {slot}:', fontsize=9)\n",
    "    for v in range(8):\n",
    "        rect = plt.Rectangle((2 + v * 0.6, y_base), 0.55, 0.5, \n",
    "                             facecolor='#e74c3c', edgecolor='black', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(2 + v * 0.6 + 0.275, y_base + 0.25, f'v{v}', \n",
    "                ha='center', va='center', fontsize=7)\n",
    "\n",
    "# Load slots (2 slots)\n",
    "ax.text(8, 6.5, 'Load (2 slots):', fontsize=11, fontweight='bold')\n",
    "for slot in range(2):\n",
    "    y_base = 5.5 - slot * 0.9\n",
    "    for v in range(8):\n",
    "        rect = plt.Rectangle((8 + v * 0.6, y_base), 0.55, 0.5, \n",
    "                             facecolor='#3498db', edgecolor='black', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# Store slots (2 slots)\n",
    "ax.text(8, 3.7, 'Store (2 slots):', fontsize=11, fontweight='bold')\n",
    "for slot in range(2):\n",
    "    y_base = 2.7 - slot * 0.9\n",
    "    for v in range(8):\n",
    "        rect = plt.Rectangle((8 + v * 0.6, y_base), 0.55, 0.5, \n",
    "                             facecolor='#2ecc71', edgecolor='black', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# Summary\n",
    "ax.text(7, 0.5, f'Total in ONE cycle: {6*8} computes + {2*8} loads + {2*8} stores = {6*8 + 2*8 + 2*8} value operations!',\n",
    "        ha='center', fontsize=11, fontweight='bold', \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-insight",
   "metadata": {},
   "source": [
    "In a single cycle, our challenge machine can potentially:\n",
    "- Compute 48 values (6 valu slots x 8 values each)\n",
    "- Load 16 values (2 load slots x 8 values each)\n",
    "- Store 16 values (2 store slots x 8 values each)\n",
    "\n",
    "That's up to **80 value operations per cycle** when everything is perfectly scheduled!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "full-pipeline-example",
   "metadata": {},
   "source": [
    "### A Full Pipeline Example\n",
    "\n",
    "Let's trace through a realistic example: processing 32 values (4 batches of 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a fully pipelined execution\n",
    "def simulate_full_pipeline(n_values, vlen=8):\n",
    "    n_batches = (n_values + vlen - 1) // vlen\n",
    "    \n",
    "    print(f\"Processing {n_values} values in {n_batches} batches of {vlen}\")\n",
    "    print(\"\\nPipeline execution:\")\n",
    "    print(f\"{'Cycle':<8} {'Load':<15} {'Compute':<15} {'Store':<15}\")\n",
    "    print(\"-\" * 53)\n",
    "    \n",
    "    total_cycles = n_batches + 2  # Fill + drain\n",
    "    \n",
    "    for cycle in range(total_cycles):\n",
    "        load_batch = cycle if cycle < n_batches else '-'\n",
    "        compute_batch = cycle - 1 if 0 <= cycle - 1 < n_batches else '-'\n",
    "        store_batch = cycle - 2 if 0 <= cycle - 2 < n_batches else '-'\n",
    "        \n",
    "        load_str = f'Batch {load_batch}' if load_batch != '-' else '(idle)'\n",
    "        compute_str = f'Batch {compute_batch}' if compute_batch != '-' else '(idle)'\n",
    "        store_str = f'Batch {store_batch}' if store_batch != '-' else '(idle)'\n",
    "        \n",
    "        print(f\"{cycle:<8} {load_str:<15} {compute_str:<15} {store_str:<15}\")\n",
    "    \n",
    "    return total_cycles\n",
    "\n",
    "cycles = simulate_full_pipeline(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to non-pipelined execution\n",
    "n_values = 32\n",
    "n_batches = 4\n",
    "\n",
    "sequential_cycles = n_batches * 3  # 3 stages per batch\n",
    "pipelined_cycles = n_batches + 2    # Pipeline overhead\n",
    "\n",
    "print(f\"Sequential (no pipeline): {sequential_cycles} cycles\")\n",
    "print(f\"Pipelined VLIW: {pipelined_cycles} cycles\")\n",
    "print(f\"Speedup: {sequential_cycles / pipelined_cycles:.1f}x\")\n",
    "print(f\"\\nWith more batches, the speedup approaches 3x (the pipeline depth)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottleneck-intro",
   "metadata": {},
   "source": [
    "## The Bottleneck Game\n",
    "\n",
    "In theory, we have 48 compute values per cycle but only 16 load values per cycle. In practice, this means **memory bandwidth is often the bottleneck**, not compute.\n",
    "\n",
    "Let's explore this with a concrete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottleneck-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Element-wise multiply of two arrays, store result\n",
    "# For each output element, we need:\n",
    "# - 2 loads (one from each input array)\n",
    "# - 1 multiply\n",
    "# - 1 store\n",
    "\n",
    "print(\"Operation: result[i] = a[i] * b[i]\")\n",
    "print(\"\\nPer element:\")\n",
    "print(\"  Loads needed: 2 (a[i] and b[i])\")\n",
    "print(\"  Computes needed: 1 (multiply)\")\n",
    "print(\"  Stores needed: 1 (result[i])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottleneck-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many elements can we process per cycle?\n",
    "load_slots = 2\n",
    "store_slots = 2\n",
    "valu_slots = 6\n",
    "vlen = 8\n",
    "\n",
    "# Memory perspective: 2 loads needed per element\n",
    "# With 2 load slots, we can do 2 vloads = 16 values loaded\n",
    "# But we need 2 loads per output element, so that's 8 output elements\n",
    "loads_per_cycle = load_slots * vlen  # 16 values loaded\n",
    "loads_per_output = 2  # Need 2 arrays\n",
    "max_outputs_from_loads = loads_per_cycle // loads_per_output  # 8 outputs\n",
    "\n",
    "# Compute perspective: 1 multiply per output element\n",
    "# With 6 valu slots, we could do 6 vmuls = 48 values\n",
    "computes_per_cycle = valu_slots * vlen  # 48 values\n",
    "computes_per_output = 1\n",
    "max_outputs_from_compute = computes_per_cycle // computes_per_output  # 48 outputs\n",
    "\n",
    "# Store perspective: 1 store per output\n",
    "stores_per_cycle = store_slots * vlen  # 16 values\n",
    "stores_per_output = 1\n",
    "max_outputs_from_stores = stores_per_cycle // stores_per_output  # 16 outputs\n",
    "\n",
    "print(\"Throughput analysis for a[i] * b[i]:\")\n",
    "print(f\"  From load capacity: {max_outputs_from_loads} outputs/cycle\")\n",
    "print(f\"  From compute capacity: {max_outputs_from_compute} outputs/cycle\")\n",
    "print(f\"  From store capacity: {max_outputs_from_stores} outputs/cycle\")\n",
    "print(f\"\\nBottleneck: {min(max_outputs_from_loads, max_outputs_from_compute, max_outputs_from_stores)} outputs/cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottleneck-visual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bottleneck\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "categories = ['Load\\n(2 slots)', 'Compute\\n(6 valu slots)', 'Store\\n(2 slots)']\n",
    "capacities = [max_outputs_from_loads, max_outputs_from_compute, max_outputs_from_stores]\n",
    "colors_bar = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "bars = ax.bar(categories, capacities, color=colors_bar, edgecolor='black')\n",
    "\n",
    "# Highlight the bottleneck\n",
    "min_cap = min(capacities)\n",
    "for bar, cap in zip(bars, capacities):\n",
    "    if cap == min_cap:\n",
    "        bar.set_edgecolor('red')\n",
    "        bar.set_linewidth(3)\n",
    "\n",
    "# Bottleneck line\n",
    "ax.axhline(y=min_cap, color='red', linestyle='--', linewidth=2, label=f'Bottleneck: {min_cap} outputs/cycle')\n",
    "\n",
    "ax.set_ylabel('Max outputs per cycle')\n",
    "ax.set_title('For a[i] * b[i]: Load is the bottleneck!\\n(We have compute capacity for 48 but can only load for 8)', fontsize=11)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, cap in zip(bars, capacities):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            str(cap), ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottleneck-lesson",
   "metadata": {},
   "source": [
    "**Key insight**: Even though we have 6 vector ALU slots (capable of 48 computations per cycle), we can only feed them with 2 load slots. For this workload, we're **memory-bound**, not compute-bound.\n",
    "\n",
    "This is extremely common in practice. Modern CPUs have so much compute power that the challenge is often getting data to the compute units fast enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice-bottleneck",
   "metadata": {},
   "source": [
    "### Practice: Find the Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-bottleneck-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: result[i] = (a[i] + b[i]) * (c[i] - d[i])\n",
    "# Per output element:\n",
    "# - Loads: 4 (a, b, c, d)\n",
    "# - Computes: 3 (add, subtract, multiply)\n",
    "# - Stores: 1\n",
    "\n",
    "print(\"Operation: result[i] = (a[i] + b[i]) * (c[i] - d[i])\")\n",
    "print(\"\\nYour task: Calculate the bottleneck\")\n",
    "print(f\"  Load slots: {load_slots}, each loads {vlen} values\")\n",
    "print(f\"  VALU slots: {valu_slots}, each computes {vlen} values\")\n",
    "print(f\"  Store slots: {store_slots}, each stores {vlen} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-bottleneck-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "loads_needed_per_output = 4\n",
    "computes_needed_per_output = 3\n",
    "stores_needed_per_output = 1\n",
    "\n",
    "test_max_from_loads = (load_slots * vlen) // loads_needed_per_output\n",
    "test_max_from_compute = (valu_slots * vlen) // computes_needed_per_output  \n",
    "test_max_from_stores = (store_slots * vlen) // stores_needed_per_output\n",
    "\n",
    "test_bottleneck = min(test_max_from_loads, test_max_from_compute, test_max_from_stores)\n",
    "\n",
    "print(f\"Max outputs from loads: {test_max_from_loads}\")\n",
    "print(f\"Max outputs from compute: {test_max_from_compute}\")\n",
    "print(f\"Max outputs from stores: {test_max_from_stores}\")\n",
    "print(f\"\\nBottleneck: {test_bottleneck} outputs/cycle\")\n",
    "\n",
    "# Verify\n",
    "assert test_bottleneck == 4, f\"Expected bottleneck of 4, got {test_bottleneck}\"\n",
    "print(\"Correct! Load is still the bottleneck (4 loads needed per output, only 2 load slots)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compute-bound-example",
   "metadata": {},
   "source": [
    "### When Compute IS the Bottleneck\n",
    "\n",
    "Sometimes compute can be the bottleneck - when you're doing lots of operations on data that's already loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-bound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Apply 10 sequential operations to data already in registers\n",
    "# (e.g., a complex hash function with many steps)\n",
    "\n",
    "# Data is loaded ONCE, then we do many operations\n",
    "loads_per_output = 1\n",
    "computes_per_output = 10  # Hash function has many steps\n",
    "stores_per_output = 1\n",
    "\n",
    "max_from_loads = (load_slots * vlen) // loads_per_output\n",
    "max_from_compute = (valu_slots * vlen) // computes_per_output\n",
    "max_from_stores = (store_slots * vlen) // stores_per_output\n",
    "\n",
    "print(\"Scenario: Hash function with 10 sequential operations\")\n",
    "print(f\"  Max from loads: {max_from_loads} outputs/cycle\")\n",
    "print(f\"  Max from compute: {max_from_compute} outputs/cycle\")\n",
    "print(f\"  Max from stores: {max_from_stores} outputs/cycle\")\n",
    "print(f\"\\nNow COMPUTE is the bottleneck! ({max_from_compute} < {max_from_loads})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary: Two Dimensions of Parallelism\n",
    "\n",
    "We've explored two complementary forms of CPU parallelism:\n",
    "\n",
    "### SIMD (Single Instruction, Multiple Data)\n",
    "- **What**: Process VLEN values with one instruction\n",
    "- **How**: Vector registers + vector operations (vload, vstore, valu)\n",
    "- **Key requirement**: Data must be contiguous in memory\n",
    "- **Speedup**: Up to VLEN (8x on our machine)\n",
    "\n",
    "### VLIW (Very Long Instruction Word)\n",
    "- **What**: Execute multiple operations using different hardware in one cycle\n",
    "- **How**: Bundle operations for ALU, load, store, flow into one instruction\n",
    "- **Key insight**: Different engines can work in parallel\n",
    "- **Enables**: Pipelining (load batch N+1 while computing batch N)\n",
    "\n",
    "### Combined Power\n",
    "Our challenge machine can potentially do:\n",
    "- 6 vector ALU ops x 8 values = 48 computes/cycle\n",
    "- 2 vector loads x 8 values = 16 loads/cycle  \n",
    "- 2 vector stores x 8 values = 16 stores/cycle\n",
    "\n",
    "### The Bottleneck Reality\n",
    "- Theoretical throughput is limited by the scarcest resource\n",
    "- Often memory-bound (loads are precious!)\n",
    "- Scheduling operations to maximize slot usage is the art of VLIW programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Quick reference\n",
    "print(\"Challenge Machine Quick Reference\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"VLEN = {VLEN} (values per vector operation)\")\n",
    "print(\"\\nSlot limits per cycle:\")\n",
    "for engine, slots in SLOT_LIMITS.items():\n",
    "    if engine != 'debug':\n",
    "        print(f\"  {engine:6s}: {slots:2d}\")\n",
    "print(\"\\nMax throughput per cycle:\")\n",
    "print(f\"  Compute: {SLOT_LIMITS['valu'] * VLEN} values (valu) + {SLOT_LIMITS['alu']} values (alu)\")\n",
    "print(f\"  Load:    {SLOT_LIMITS['load'] * VLEN} values\")\n",
    "print(f\"  Store:   {SLOT_LIMITS['store'] * VLEN} values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}