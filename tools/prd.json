{
  "project": "VLIW SIMD Optimization Tools",
  "goal": "Build tools to push cycle count below 1,487 (currently at 8,500)",
  "current_cycles": 8500,
  "target_cycles": 1487,
  "tools": [
    {
      "id": "slot_analyzer",
      "name": "Slot Utilization Analyzer",
      "file": "slot_analyzer.py",
      "status": "completed",
      "priority": "P0",
      "description": "Analyzes instruction streams for slot utilization and packing opportunities",
      "features": {
        "overall_utilization": true,
        "per_engine_breakdown": true,
        "histogram": true,
        "packing_opportunities": true,
        "packing_by_type": true,
        "json_output": true,
        "dependency_analysis": true,
        "critical_path": true,
        "recommendations": true,
        "kernel_diff": true,
        "rich_output": true,
        "save_load_kernels": true
      },
      "usage": "python tools/slot_analyzer.py [--packing] [--deps] [--recommendations] [--compare k1.json k2.json] [--save file.json]",
      "future_improvements": [
        "Full DAG for critical path (currently adjacent-only)",
        "Hot register detection",
        "Instruction latency model",
        "Modularize into separate files"
      ]
    },
    {
      "id": "dependency_graph",
      "name": "Dependency Graph Builder",
      "file": "dependency_graph/dependency_graph.py",
      "status": "completed",
      "priority": "P0",
      "description": "Build full DAG of instruction dependencies (RAW, WAR, WAW hazards)",
      "features": {
        "build_dag": true,
        "critical_path": true,
        "parallelism_potential": true,
        "hot_registers": true,
        "rich_output": true,
        "json_output": true
      },
      "usage": "python tools/dependency_graph/dependency_graph.py [--json] [--top N]",
      "value": "Essential for understanding what PREVENTS packing"
    },
    {
      "id": "vliw_packer",
      "name": "VLIW Auto-Packer",
      "file": "vliw_packer/vliw_packer.py",
      "status": "completed",
      "priority": "P0",
      "description": "Automatically pack independent instructions into VLIW bundles",
      "features": {
        "dependency_aware": true,
        "respects_slot_limits": true,
        "priority_scheduling": true,
        "outputs_packed_kernel": true,
        "statistics_report": true
      },
      "usage": "python tools/vliw_packer/vliw_packer.py [--output FILE] [--verbose]",
      "value": "Achieves ~1.4x speedup automatically"
    },
    {
      "id": "cycle_profiler",
      "name": "Cycle Profiler",
      "file": "cycle_profiler/cycle_profiler.py",
      "status": "completed",
      "priority": "P1",
      "description": "Break down cycles by code section (hash, memory, index calc)",
      "features": {
        "phase_tagging": true,
        "per_round_breakdown": true,
        "hotspot_identification": true,
        "rich_output": true,
        "json_output": true,
        "optimization_recommendations": true,
        "exclusive_cycle_tracking": true
      },
      "usage": "python tools/cycle_profiler/cycle_profiler.py [--all] [--detailed] [--per-round] [--recommendations] [--json]",
      "value": "Know WHERE cycles are spent, not just how many"
    },
    {
      "id": "memory_analyzer",
      "name": "Memory Access Pattern Analyzer",
      "file": "memory_analyzer/memory_analyzer.py",
      "status": "completed",
      "priority": "P1",
      "description": "Analyze load/store patterns for vectorization opportunities",
      "features": {
        "access_pattern_detection": true,
        "stride_analysis": true,
        "vectorization_blockers": true,
        "address_source_tracking": true,
        "rich_output": true,
        "json_output": true,
        "recommendations": true
      },
      "usage": "python tools/memory_analyzer/memory_analyzer.py [--json] [--verbose] [--no-color]",
      "value": "Reveals why vload/vstore can't be used (tree lookups = scattered addresses)"
    },
    {
      "id": "hash_pipeline",
      "name": "Hash Pipeline Analyzer",
      "file": "hash_pipeline/hash_pipeline.py",
      "status": "completed",
      "priority": "P1",
      "description": "ILP analysis tool for 6-stage hash function software pipelining",
      "features": {
        "stage_dependency_analysis": true,
        "intra_stage_parallelism": true,
        "inter_element_pipelining": true,
        "scheduling_strategies": true,
        "theoretical_minimum_calc": true,
        "realistic_estimates": true,
        "batch_size_analysis": true,
        "code_generation_hints": true,
        "schedule_visualization": true,
        "json_output": true
      },
      "usage": "python tools/hash_pipeline/hash_pipeline.py [--elements N] [--visualize] [--codegen] [--realistic]",
      "value": "Hash is the hottest code path (4096 calls) - understanding ILP is critical",
      "notes": [
        "Provides THEORETICAL lower bounds, not achievable targets",
        "Real implementations will have additional overhead",
        "Always validate with slot_analyzer on actual code"
      ]
    },
    {
      "id": "constraint_validator",
      "name": "Constraint Validator",
      "file": "constraint_validator/constraint_validator.py",
      "status": "completed",
      "priority": "P2",
      "description": "Static checking of kernel before runtime",
      "features": {
        "slot_limit_check": true,
        "scratch_overflow_check": true,
        "same_cycle_hazard_check": true,
        "register_usage_validation": true,
        "rich_output": true,
        "json_output": true,
        "strict_mode": true
      },
      "usage": "python tools/constraint_validator/constraint_validator.py [--json] [--strict] [--kernel FILE]",
      "value": "Catch errors before slow runtime failures"
    },
    {
      "id": "transforms",
      "name": "Transformation Library",
      "file": "transforms/transforms.py",
      "status": "completed",
      "priority": "P2",
      "description": "Codified transformations: unroll, vectorize, pipeline, hoist invariants",
      "features": {
        "loop_unroll": true,
        "vectorize_batch": true,
        "software_pipeline": true,
        "hoist_invariants": true,
        "rich_output": true,
        "json_output": true,
        "hash_helpers": true,
        "analysis_tools": true
      },
      "usage": "python tools/transforms/transforms.py [--demo] [--json]",
      "value": "Reduces manual errors in mechanical transforms"
    },
    {
      "id": "kernel_diff",
      "name": "Kernel Diff Tool",
      "file": "kernel_diff/kernel_diff.py",
      "status": "completed",
      "priority": "P2",
      "description": "Compare two kernel versions (cycles, utilization, structure)",
      "features": {
        "cycle_comparison": true,
        "utilization_diff": true,
        "instruction_diff": true,
        "side_by_side_view": true,
        "rich_output": true,
        "json_output": true,
        "baseline_comparison": true,
        "save_kernel": true
      },
      "usage": "python tools/kernel_diff/kernel_diff.py kernel1.json kernel2.json [--baseline FILE] [--save FILE] [--json] [-v]",
      "value": "Track impact of each optimization"
    },
    {
      "id": "optimization_loop",
      "name": "Optimization Loop Runner",
      "file": "optimization_loop/optimize.py",
      "status": "completed",
      "priority": "P3",
      "description": "Meta-tool that runs profile->analyze->transform->validate loop",
      "features": {
        "automated_profiling": true,
        "bottleneck_detection": true,
        "transform_suggestions": true,
        "regression_checking": true,
        "rich_output": true,
        "json_output": true,
        "dry_run_mode": true
      },
      "usage": "python tools/optimization_loop/optimize.py [--profile] [--suggest] [--validate] [--json] [--dry-run]",
      "value": "Automates the optimization search process"
    },
    {
      "id": "register_pressure",
      "name": "Register Pressure Analyzer",
      "file": "register_pressure/register_pressure.py",
      "status": "completed",
      "priority": "P2",
      "description": "Analyze scratch memory usage patterns and register pressure over kernel execution",
      "features": {
        "live_range_tracking": true,
        "pressure_computation": true,
        "peak_detection": true,
        "reuse_opportunities": true,
        "pressure_visualization": true,
        "limit_warnings": true,
        "rich_output": true,
        "json_output": true
      },
      "usage": "python tools/register_pressure/register_pressure.py [--all] [--peaks] [--reuse] [--visualize] [--json]",
      "value": "Determine if more unrolling/pipelining is feasible based on scratch memory headroom"
    },
    {
      "id": "dsl_compiler",
      "name": "DSL Compiler",
      "file": "dsl_compiler/dsl_compiler.py",
      "status": "completed",
      "priority": "P1",
      "description": "High-level DSL compiler for expressing algorithms in Python-like syntax, compiles to optimized VLIW instructions",
      "features": {
        "python_like_syntax": true,
        "automatic_vectorization": true,
        "hash_expansion": true,
        "dependency_analysis": true,
        "vliw_scheduling": true,
        "scratch_allocation": true,
        "loop_unrolling": true,
        "memory_operations": true,
        "rich_output": true,
        "json_output": true,
        "kernel_builder_compatible": true
      },
      "usage": "python tools/dsl_compiler/dsl_compiler.py <file.dsl> [--json] [--demo] [--no-vectorize]",
      "value": "Write algorithms at high level, compile to optimal VLIW - enables rapid iteration without manual instruction writing",
      "notes": [
        "Loops must be compile-time unrollable (no dynamic bounds)",
        "Hash function expands to 6-stage implementation automatically",
        "Use @vectorize(8) decorator for automatic vectorization"
      ]
    },
    {
      "id": "hash_superopt",
      "name": "Hash Stage Superoptimizer",
      "file": "hash_superopt/hash_superopt.py",
      "status": "completed",
      "priority": "P0",
      "description": "Exhaustively enumerates ALL legal schedules for hash operations to find THE provably optimal schedule",
      "features": {
        "exhaustive_enumeration": true,
        "single_stage_analysis": true,
        "multi_stage_analysis": true,
        "multi_batch_pipelining": true,
        "batch_scaling_analysis": true,
        "instruction_emission": true,
        "pareto_optimal_schedules": true,
        "optimality_proof": true,
        "rich_output": true,
        "json_output": true
      },
      "usage": "python tools/hash_superopt/hash_superopt.py [--stages N] [--batches N] [--scale] [--emit] [--json] [--pareto]",
      "value": "Proves optimal hash schedule: 3-batch pipelining gives 4 cycles/hash (3x speedup, 75% VALU utilization)",
      "key_findings": {
        "single_hash_cycles": 12,
        "optimal_batches": 3,
        "cycles_per_hash_optimal": 4.0,
        "speedup": "3.0x",
        "valu_utilization": "75%"
      },
      "notes": [
        "Unlike heuristics, guarantees optimal through exhaustive search",
        "3-batch pipelining fills all 6 VALU slots for tmp1+tmp2 cycles",
        "Impact: reduces hash from 49,152 to 16,384 cycles for full kernel"
      ]
    }
  ],
  "libraries_to_install": [
    {"name": "networkx", "purpose": "Dependency graphs", "installed": false},
    {"name": "rich", "purpose": "Terminal output", "installed": false},
    {"name": "ortools", "purpose": "Constraint solving for scheduling", "installed": false}
  ],
  "milestones": [
    {"cycles": 18532, "name": "2-hour starting point", "achieved": true},
    {"cycles": 8500, "name": "Current position", "achieved": true},
    {"cycles": 2164, "name": "Opus 4 many hours", "achieved": false},
    {"cycles": 1790, "name": "Opus 4.5 casual", "achieved": false},
    {"cycles": 1487, "name": "TARGET: Opus 4.5 11.5hr", "achieved": false}
  ]
}
